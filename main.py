"""
åŸç¥OCRè®­ç»ƒä¸»ç¨‹åº - ä¼˜åŒ–ç‰ˆ
æ•´åˆè®­ç»ƒã€éªŒè¯ã€è½¬æ¢ç­‰æ ¸å¿ƒåŠŸèƒ½ï¼Œæ·»åŠ é…ç½®ç®¡ç†å’Œæ€§èƒ½ä¼˜åŒ–æ”¯æŒ
"""

import argparse
import torch
import torch.nn as nn
import gc
import os
import sys
from pathlib import Path

from mona.config import config, get_config_manager, optimize_for_rtx4060ti, print_optimization_status
from mona.utils import logger
from train import train as train_model


def cleanup_gpu():
    """GPUèµ„æºæ¸…ç† - ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
    if torch.cuda.is_available():
        # ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–å™¨çš„æ¸…ç†åŠŸèƒ½
        try:
            from mona.training.performance_optimizer import PerformanceOptimizer
            optimizer = PerformanceOptimizer({})
            optimizer.cleanup_memory(aggressive=True)
            logger.info("âœ… GPUèµ„æºå·²æ¸…ç†ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
        except ImportError:
            # å›é€€åˆ°åŸºç¡€æ¸…ç†
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
            logger.info("âœ… GPUèµ„æºå·²æ¸…ç†ï¼ˆåŸºç¡€ç‰ˆï¼‰")
    else:
        logger.info("â„¹ï¸ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡")


def system_check():
    """å¢å¼ºçš„ç³»ç»Ÿæ£€æŸ¥"""
    logger.info("ğŸ”§ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    logger.info("=" * 40)
    
    # è·å–é…ç½®ç®¡ç†å™¨
    config_manager = get_config_manager()
    
    # GPUæ£€æŸ¥
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        memory_used = torch.cuda.memory_allocated(0) / 1024**3
        logger.info(f"ğŸ® GPU: {gpu_name}")
        logger.info(f"ğŸ’¾ æ˜¾å­˜: {gpu_memory:.1f}GB (å·²ä½¿ç”¨: {memory_used:.1f}GB)")
        
        # RTX 4060 TIæ£€æµ‹
        if "4060" in gpu_name:
            logger.info("ğŸ¯ æ£€æµ‹åˆ°RTX 4060 TI - å¯å¯ç”¨ä¸“é¡¹ä¼˜åŒ–")
    else:
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡")
    
    # PyTorchç‰ˆæœ¬æ£€æŸ¥
    torch_version = torch.__version__
    logger.info(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch_version}")
    
    # æ£€æŸ¥torch.compileæ”¯æŒ
    if hasattr(torch, 'compile') and torch_version >= "2.0":
        logger.info("âœ… æ”¯æŒtorch.compileä¼˜åŒ–")
        if not config_manager.hardware["compile_model"]:
            logger.info("ğŸ’¡ å»ºè®®å¯ç”¨æ¨¡å‹ç¼–è¯‘: python main.py optimize --enable-compile")
    else:
        logger.info("âš ï¸ ä¸æ”¯æŒtorch.compileï¼ˆéœ€è¦PyTorch 2.0+ï¼‰")
    
    # æ··åˆç²¾åº¦æ£€æŸ¥
    if config_manager.hardware["mixed_precision"]:
        logger.info("ğŸš€ æ··åˆç²¾åº¦è®­ç»ƒ: å·²å¯ç”¨")
    else:
        logger.info("ğŸ’¡ æ··åˆç²¾åº¦è®­ç»ƒ: æœªå¯ç”¨ - å»ºè®®å¯ç”¨ä»¥æå‡æ€§èƒ½")
    
    # é…ç½®æ£€æŸ¥
    logger.info(f"ğŸ“¦ Batch Size: {config_manager.get('training', 'batch_size')}")
    logger.info(f"ğŸ”„ è®­ç»ƒè½®æ•°: {config_manager.get('training', 'epoch')}")
    logger.info(f"ğŸ’¾ æ¨¡å‹ä¿å­˜é˜ˆå€¼: {config_manager.get('training', 'model_save_threshold')}")
    
    logger.info("=" * 40)


def generate_samples(count=10):
    """ç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
    from mona.datagen.datagen import DataGen
    from mona.text import get_lexicon
    from PIL import ImageFont
    
    # åˆå§‹åŒ–
    lexicon = get_lexicon()
    fonts = [ImageFont.truetype("./assets/genshin.ttf", i) for i in range(15, 90)]
    datagen = DataGen(config, fonts, lexicon)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("samples", exist_ok=True)
    
    logger.info(f"ğŸ“¸ ç”Ÿæˆ {count} ä¸ªæ ·æœ¬...")
    for i in range(count):
        im, text = datagen.generate_image()
        im.save(f"samples/sample_{i:03d}_{text}.png")
    
    logger.info(f"âœ… å·²ç”Ÿæˆ {count} ä¸ªæ ·æœ¬åˆ° samples/ ç›®å½•")


def validate_model(model_path):
    """éªŒè¯æ¨¡å‹"""
    if not os.path.exists(model_path):
        logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    from mona.nn.model2 import Model2
    from mona.text import get_lexicon
    from mona.nn import predict as predict_net
    from mona.datagen.datagen import DataGen
    from PIL import ImageFont
    import torchvision.transforms as transforms
    
    # åŠ è½½æ¨¡å‹
    lexicon = get_lexicon()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    net = Model2(lexicon.lexicon_size(), 1).to(device)
    net.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
    net.eval()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    fonts = [ImageFont.truetype("./assets/genshin.ttf", i) for i in range(15, 90)]
    datagen = DataGen(config, fonts, lexicon)
    
    correct = 0
    total = 20  # æµ‹è¯•20ä¸ªæ ·æœ¬
    
    logger.info("ğŸ” å¼€å§‹éªŒè¯...")
    with torch.no_grad():
        for i in range(total):
            im, true_text = datagen.generate_image()
            tensor = transforms.ToTensor()(im).unsqueeze(0).to(device)
            
            predicted = predict_net(net, tensor, lexicon)
            if predicted[0] == true_text:
                correct += 1
            
            if i < 5:  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                logger.info(f"çœŸå®: {true_text} | é¢„æµ‹: {predicted[0]} | {'âœ“' if predicted[0] == true_text else 'âœ—'}")
    
    accuracy = correct / total
    logger.info(f"ğŸ“Š éªŒè¯å®Œæˆ: {correct}/{total} ({accuracy:.2%})")


def convert_to_onnx(model_path, output_path=None):
    """è½¬æ¢æ¨¡å‹ä¸ºONNXæ ¼å¼"""
    if not os.path.exists(model_path):
        logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    from mona.nn.model2 import Model2
    from mona.text import get_lexicon
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = model_path.replace('.pt', '.onnx')
    
    lexicon = get_lexicon()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # åŠ è½½æ¨¡å‹
    net = Model2(lexicon.lexicon_size(), 1).to(device)
    net.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
    net.eval()
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(1, 1, 32, 384).to(device)
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        net,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    logger.info(f"ğŸ“„ ONNXæ¨¡å‹å·²ä¿å­˜: {output_path}")


def list_models():
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹æ–‡ä»¶"""
    models_dir = Path("models")
    if not models_dir.exists():
        logger.warning("âš ï¸ modelsç›®å½•ä¸å­˜åœ¨")
        return
    
    model_files = list(models_dir.glob("*.pt"))
    if not model_files:
        logger.info("ğŸ“‚ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return
    
    logger.info("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    for model_file in sorted(model_files):
        size = model_file.stat().st_size / 1024 / 1024  # MB
        logger.info(f"  ğŸ“„ {model_file.name} ({size:.1f}MB)")


def evaluate_models(args):
    """æ‰¹é‡è¯„ä¼°æ¨¡å‹ - åœ¨çº¿æ•°æ®ç”Ÿæˆç‰ˆ"""
    try:
        from scripts.model_evaluator import ModelEvaluator
        
        logger.info("ğŸš€ å¯åŠ¨æ¨¡å‹è¯„ä¼°ï¼ˆåœ¨çº¿æ•°æ®ç”Ÿæˆç‰ˆï¼‰...")
        
        # åˆå§‹åŒ–è¯„ä¼°å™¨
        evaluator = ModelEvaluator("models")
        
        if args.single:
            # è¯„ä¼°å•ä¸ªæ¨¡å‹
            model_path = Path(args.single)
            if not model_path.exists():
                logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return
            
            result = evaluator.evaluate_single_model(model_path, args.test_size)
            if result:
                logger.info(f"\nğŸ‰ å•æ¨¡å‹è¯„ä¼°å®Œæˆ:")
                logger.info(f"   ğŸ“„ æ¨¡å‹: {result['model_name']}")
                logger.info(f"   ğŸ¯ å‡†ç¡®ç‡: {result['exact_accuracy']:.6f}")
                logger.info(f"   ğŸ“ å­—ç¬¦å‡†ç¡®ç‡: {result['char_accuracy']:.6f}")
                logger.info(f"   âš¡ é€Ÿåº¦: {result['avg_inference_time_ms']:.2f}ms")
                logger.info(f"   ğŸ† ç»¼åˆè¯„åˆ†: {result['overall_score']:.6f}")
                logger.info(f"   ğŸ“Š å®é™…æµ‹è¯•æ ·æœ¬: {result['total_samples']:,}")
        else:
            # æ‰¹é‡è¯„ä¼°
            results = evaluator.evaluate_all_models(args.test_size)
            
            if results:
                # ç”ŸæˆæŠ¥å‘Š
                report_file = evaluator.generate_report("logs")
                
                # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
                best_model = evaluator.get_best_model()
                logger.info(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['model_name']}")
                logger.info(f"   ğŸ¯ å‡†ç¡®ç‡: {best_model['exact_accuracy']:.6f}")
                logger.info(f"   ğŸ“ å­—ç¬¦å‡†ç¡®ç‡: {best_model['char_accuracy']:.6f}")
                logger.info(f"   âš¡ é€Ÿåº¦: {best_model['avg_inference_time_ms']:.2f}ms")
                logger.info(f"   ğŸ† ç»¼åˆè¯„åˆ†: {best_model['overall_score']:.6f}")
                logger.info(f"   ğŸ“Š æµ‹è¯•æ ·æœ¬: {best_model['total_samples']:,}")
                
                # æ˜¾ç¤ºæ¨¡å‹å·®å¼‚ç»Ÿè®¡
                if len(results) > 1:
                    accuracies = [r["exact_accuracy"] for r in results]
                    worst_model = results[-1]
                    accuracy_diff = best_model["exact_accuracy"] - worst_model["exact_accuracy"]
                    logger.info(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½å·®å¼‚:")
                    logger.info(f"   æœ€ä½³ vs æœ€å·®: {accuracy_diff:.6f} ({accuracy_diff*100:.4f}%)")
                    logger.info(f"   å‡†ç¡®ç‡æ ‡å‡†å·®: {__import__('numpy').std(accuracies):.6f}")
                
                # å¤åˆ¶æœ€ä½³æ¨¡å‹
                if args.copy_best:
                    evaluator.copy_best_model()
                
                logger.info(f"\nğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            else:
                logger.error("âŒ è¯„ä¼°å¤±è´¥æˆ–æœªæ‰¾åˆ°æ¨¡å‹")
    
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥è¯„ä¼°æ¨¡å—å¤±è´¥: {e}")
        logger.info("ğŸ’¡ è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²å®‰è£…: pip install pandas matplotlib seaborn")
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")


def competitive_evaluate_models(args):
    """ç«äº‰å¼å¹¶è¡Œæ¨¡å‹è¯„ä¼° - é”™è¯¯å³æ·˜æ±°"""
    try:
        from scripts.competitive_evaluator import CompetitiveEvaluator
        
        logger.info("ğŸ å¯åŠ¨ç«äº‰å¼æ¨¡å‹è¯„ä¼°...")
        logger.info("ğŸ’¥ è§„åˆ™: æ‰€æœ‰æ¨¡å‹åŒæ—¶ç«äº‰ï¼Œå‡ºé”™å³æ·˜æ±°ï¼Œæœ€åå­˜æ´»è€…è·èƒœ")
        logger.info("ğŸŒŠ æ— é™åœ¨çº¿æ•°æ®ç”Ÿæˆï¼ŒçœŸæ­£çš„é²æ£’æ€§æµ‹è¯•")
        
        # åˆå§‹åŒ–ç«äº‰å¼è¯„ä¼°å™¨
        evaluator = CompetitiveEvaluator("models", args.max_workers)
        
        # è¿è¡Œç«äº‰å¼è¯„ä¼°
        report = evaluator.run_competitive_evaluation(
            min_survival_time=args.min_survival_time,
            max_evaluation_time=args.max_evaluation_time
        )
        
        if report:
            # ä¿å­˜æŠ¥å‘Š
            evaluator.save_report(report, "logs")
            
            # å¤åˆ¶è·èƒœæ¨¡å‹
            if args.copy_winner:
                evaluator.copy_winner_model(report)
        else:
            logger.error("âŒ ç«äº‰å¼è¯„ä¼°å¤±è´¥")
    
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥ç«äº‰å¼è¯„ä¼°æ¨¡å—å¤±è´¥: {e}")
        logger.info("ğŸ’¡ è¯·ç¡®ä¿é¡¹ç›®ç»“æ„æ­£ç¡®ï¼Œscripts/competitive_evaluator.py å­˜åœ¨")
    except Exception as e:
        logger.error(f"âŒ ç«äº‰å¼è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")


def handle_optimization_commands(args):
    """å¤„ç†ä¼˜åŒ–ç›¸å…³å‘½ä»¤"""
    config_manager = get_config_manager()
    
    if args.action == "status":
        config_manager.print_config_summary()
        print_optimization_status()
    
    elif args.action == "enable-mixed-precision":
        from mona.config import enable_mixed_precision
        enable_mixed_precision()
    
    elif args.action == "enable-compile":
        from mona.config import enable_model_compilation
        enable_model_compilation()
    
    elif args.action == "rtx4060ti":
        optimize_for_rtx4060ti()
    
    elif args.action == "benchmark":
        run_performance_benchmark()
    
    else:
        logger.error(f"âŒ æœªçŸ¥çš„ä¼˜åŒ–å‘½ä»¤: {args.action}")


def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    logger.info("ğŸƒ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    try:
        from mona.training.performance_optimizer import PerformanceOptimizer
        config_manager = get_config_manager()
        
        optimizer = PerformanceOptimizer(config_manager.hardware)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_tensor = torch.randn(config["batch_size"], 1, 32, 384)
        if torch.cuda.is_available():
            test_tensor = test_tensor.cuda()
        
        import time
        
        # é¢„çƒ­
        for _ in range(10):
            with optimizer.autocast_context():
                _ = test_tensor * 2
        
        # åŸºå‡†æµ‹è¯•
        start_time = time.time()
        for i in range(100):
            with optimizer.autocast_context():
                result = test_tensor * 2
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
        
        end_time = time.time()
        avg_time = (end_time - start_time) / 100
        
        logger.info(f"âš¡ å¹³å‡å¤„ç†æ—¶é—´: {avg_time*1000:.2f}ms")
        logger.info(f"ğŸ“Š ç†è®ºååé‡: {config['batch_size']/avg_time:.1f} samples/s")
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_info = optimizer.get_memory_info()
        if "cuda_utilization" in memory_info:
            logger.info(f"ğŸ’¾ æ˜¾å­˜ä½¿ç”¨ç‡: {memory_info['cuda_utilization']:.1f}%")
        
        logger.info("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="åŸç¥OCRè®­ç»ƒå·¥å…· - ä¼˜åŒ–ç‰ˆ")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='è®­ç»ƒæ¨¡å‹')
    
    # éªŒè¯å‘½ä»¤
    validate_parser = subparsers.add_parser('validate', help='éªŒè¯æ¨¡å‹')
    validate_parser.add_argument('model', help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    
    # ç”Ÿæˆæ ·æœ¬å‘½ä»¤
    generate_parser = subparsers.add_parser('generate', help='ç”Ÿæˆè®­ç»ƒæ ·æœ¬')
    generate_parser.add_argument('--count', type=int, default=10, help='ç”Ÿæˆæ ·æœ¬æ•°é‡')
    
    # è½¬æ¢å‘½ä»¤
    convert_parser = subparsers.add_parser('convert', help='è½¬æ¢æ¨¡å‹ä¸ºONNX')
    convert_parser.add_argument('model', help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    convert_parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    # ä¼˜åŒ–å‘½ä»¤
    optimize_parser = subparsers.add_parser('optimize', help='æ€§èƒ½ä¼˜åŒ–ç®¡ç†')
    optimize_parser.add_argument('action', choices=[
        'status', 'enable-mixed-precision', 'enable-compile', 'rtx4060ti', 'benchmark'
    ], help='ä¼˜åŒ–æ“ä½œ')
    
    # å…¶ä»–å‘½ä»¤
    subparsers.add_parser('check', help='æ£€æŸ¥ç³»ç»ŸçŠ¶æ€')
    subparsers.add_parser('clean', help='æ¸…ç†GPUèµ„æº')
    subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰æ¨¡å‹')
    
    # æ–°å¢æ¨¡å‹è¯„ä¼°å‘½ä»¤
    eval_parser = subparsers.add_parser('evaluate', help='æ‰¹é‡è¯„ä¼°æ¨¡å‹ï¼ˆåœ¨çº¿æ•°æ®ç”Ÿæˆï¼‰')
    eval_parser.add_argument('--test-size', type=int, default=10000, help='æµ‹è¯•æ ·æœ¬æ•°é‡ï¼ˆåœ¨çº¿ç”Ÿæˆï¼Œé»˜è®¤10000ï¼‰')
    eval_parser.add_argument('--copy-best', action='store_true', help='å¤åˆ¶æœ€ä½³æ¨¡å‹')
    eval_parser.add_argument('--single', help='è¯„ä¼°å•ä¸ªæ¨¡å‹æ–‡ä»¶')
    
    # ç«äº‰å¼è¯„ä¼°å‘½ä»¤
    compete_parser = subparsers.add_parser('compete', help='ç«äº‰å¼å¹¶è¡Œè¯„ä¼°ï¼ˆé”™è¯¯å³æ·˜æ±°ï¼‰')
    compete_parser.add_argument('--min-survival-time', type=int, default=60, help='æœ€å°å­˜æ´»æ—¶é—´(ç§’)')
    compete_parser.add_argument('--max-evaluation-time', type=int, default=1800, help='æœ€å¤§è¯„ä¼°æ—¶é—´(ç§’)')
    compete_parser.add_argument('--max-workers', type=int, default=None, help='æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°')
    compete_parser.add_argument('--copy-winner', action='store_true', help='å¤åˆ¶è·èƒœæ¨¡å‹åˆ°models/modelsæ–‡ä»¶å¤¹')
    
    args = parser.parse_args()
    
    if args.command == 'train':
        train_model()
    elif args.command == 'validate':
        validate_model(args.model)
    elif args.command == 'generate':
        generate_samples(args.count)
    elif args.command == 'convert':
        convert_to_onnx(args.model, args.output)
    elif args.command == 'optimize':
        handle_optimization_commands(args)
    elif args.command == 'check':
        system_check()
    elif args.command == 'clean':
        cleanup_gpu()
    elif args.command == 'list':
        list_models()
    elif args.command == 'evaluate':
        evaluate_models(args)
    elif args.command == 'compete':
        competitive_evaluate_models(args)
    else:
        parser.print_help()
        
        # å¦‚æœæ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºå¿«é€Ÿå…¥é—¨
        print("\n" + "="*50)
        print("ğŸš€ å¿«é€Ÿå…¥é—¨:")
        print("  python main.py check                    # ç³»ç»Ÿæ£€æŸ¥")
        print("  python main.py optimize status          # æŸ¥çœ‹ä¼˜åŒ–çŠ¶æ€")
        print("  python main.py optimize rtx4060ti       # RTX 4060TIä¸“é¡¹ä¼˜åŒ–")
        print("  python main.py train                    # å¼€å§‹è®­ç»ƒ")
        print("  python main.py evaluate                 # æ‰¹é‡è¯„ä¼°æ¨¡å‹ï¼ˆåœ¨çº¿ç”Ÿæˆ10Kæ ·æœ¬ï¼‰")
        print("  python main.py evaluate --test-size 20000  # ä½¿ç”¨2ä¸‡æ ·æœ¬ç²¾ç¡®è¯„ä¼°")
        print("  python main.py evaluate --copy-best     # è¯„ä¼°å¹¶å¤åˆ¶æœ€ä½³æ¨¡å‹")
        print("  python main.py compete                  # ğŸ”¥ç«äº‰å¼è¯„ä¼°ï¼ˆé”™è¯¯å³æ·˜æ±°ï¼‰")
        print("  python main.py compete --copy-winner    # ç«äº‰å¼è¯„ä¼°å¹¶å¤åˆ¶å† å†›åˆ°models/modelsæ–‡ä»¶å¤¹")
        print("  python main.py list                     # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹")
        print("  python main.py optimize benchmark       # æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("="*50)


if __name__ == "__main__":
    main() 
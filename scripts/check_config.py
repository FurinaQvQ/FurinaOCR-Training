"""
é…ç½®å†²çªæ£€æŸ¥å·¥å…·
æ£€æµ‹å’Œè§£å†³base.pyä¸train_config.jsoncä¹‹é—´çš„é…ç½®é—®é¢˜
"""

import os
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from mona.config import get_config_manager, config
from mona.utils import logger


def check_config_conflicts():
    """æ£€æŸ¥é…ç½®å†²çªå’Œé—®é¢˜"""
    logger.info("ğŸ” å¼€å§‹é…ç½®å†²çªæ£€æŸ¥...")
    logger.info("=" * 50)
    
    config_manager = get_config_manager()
    issues_found = []
    warnings = []
    recommendations = []
    
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶å­˜åœ¨æ€§
    config_file = "configs/train_config.jsonc"
    if not os.path.exists(config_file):
        issues_found.append(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        recommendations.append("ğŸ’¡ å»ºè®®åˆ›å»ºé…ç½®æ–‡ä»¶ä»¥è‡ªå®šä¹‰è®­ç»ƒå‚æ•°")
    else:
        logger.info(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")
    
    # 2. æ£€æŸ¥å…³é”®é…ç½®å€¼
    batch_size = config_manager.get("training", "batch_size")
    train_size = config_manager.get("data", "train_size")
    model_threshold = config_manager.get("training", "model_save_threshold")
    
    logger.info("\nğŸ“Š å½“å‰å…³é”®é…ç½®:")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    logger.info(f"   è®­ç»ƒæ ·æœ¬æ•°: {train_size:,}")
    logger.info(f"   ä¿å­˜é˜ˆå€¼: {model_threshold}")
    
    # 3. æ£€æŸ¥é…ç½®åˆç†æ€§
    if batch_size > 256:
        warnings.append(f"âš ï¸ æ‰¹æ¬¡å¤§å°è¿‡å¤§ ({batch_size})ï¼Œå¯èƒ½å¯¼è‡´æ˜¾å­˜ä¸è¶³")
        recommendations.append("ğŸ’¡ å»ºè®®é™ä½batch_sizeåˆ°128-160ï¼ˆRTX 4060 TIï¼‰")
    
    if batch_size < 16:
        warnings.append(f"âš ï¸ æ‰¹æ¬¡å¤§å°è¿‡å° ({batch_size})ï¼Œè®­ç»ƒæ•ˆç‡è¾ƒä½")
        recommendations.append("ğŸ’¡ å»ºè®®æé«˜batch_sizeåˆ°64-128")
    
    if train_size < 10000:
        warnings.append(f"âš ï¸ è®­ç»ƒæ ·æœ¬æ•°è¿‡å°‘ ({train_size:,})ï¼Œå¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½")
        recommendations.append("ğŸ’¡ å»ºè®®å¢åŠ train_sizeåˆ°50000+")
    
    if model_threshold == 1.0:
        warnings.append("âš ï¸ ä¿å­˜é˜ˆå€¼ä¸º100%ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒå¾ˆä¹…æ‰ä¿å­˜æ¨¡å‹")
        recommendations.append("ğŸ’¡ è°ƒè¯•æ—¶å»ºè®®è®¾ç½®model_save_thresholdä¸º0.95")
    
    # 4. æ£€æŸ¥ç¡¬ä»¶ä¼˜åŒ–é…ç½®
    mixed_precision = config_manager.get("hardware", "mixed_precision")
    compile_model = config_manager.get("hardware", "compile_model")
    memory_efficient = config_manager.get("hardware", "memory_efficient")
    
    logger.info(f"\nâš¡ ç¡¬ä»¶ä¼˜åŒ–çŠ¶æ€:")
    logger.info(f"   æ··åˆç²¾åº¦: {'âœ… å·²å¯ç”¨' if mixed_precision else 'âŒ æœªå¯ç”¨'}")
    logger.info(f"   æ¨¡å‹ç¼–è¯‘: {'âœ… å·²å¯ç”¨' if compile_model else 'âŒ æœªå¯ç”¨'}")
    logger.info(f"   å†…å­˜ä¼˜åŒ–: {'âœ… å·²å¯ç”¨' if memory_efficient else 'âŒ æœªå¯ç”¨'}")
    
    if not mixed_precision:
        recommendations.append("ğŸš€ å¼ºçƒˆå»ºè®®å¯ç”¨mixed_precisionä»¥æå‡è®­ç»ƒé€Ÿåº¦")
    
    # 5. æ£€æŸ¥æ•°æ®ç­–ç•¥é…ç½®
    data_strategy = config_manager.get("data", "data_strategy", "online")
    accuracy_threshold = config_manager.get("data", "accuracy_threshold", 0.95)
    
    logger.info(f"\nğŸ§  æ•°æ®ç­–ç•¥:")
    logger.info(f"   ç­–ç•¥æ¨¡å¼: {data_strategy}")
    logger.info(f"   åˆ‡æ¢é˜ˆå€¼: {accuracy_threshold}")
    
    if data_strategy not in ["online", "fixed", "adaptive"]:
        issues_found.append(f"âŒ æ— æ•ˆçš„æ•°æ®ç­–ç•¥: {data_strategy}")
    
    # 6. æ£€æŸ¥ç¯å¢ƒå˜é‡è¦†ç›–
    env_overrides = []
    env_vars = ["BATCH_SIZE", "MIXED_PRECISION", "TRAIN_SIZE", "MODEL_SAVE_THRESHOLD"]
    
    for env_var in env_vars:
        value = os.getenv(env_var)
        if value is not None:
            env_overrides.append(f"   {env_var}={value}")
    
    if env_overrides:
        logger.info(f"\nğŸŒ ç¯å¢ƒå˜é‡è¦†ç›–:")
        for override in env_overrides:
            logger.info(override)
    else:
        logger.info(f"\nğŸŒ æ— ç¯å¢ƒå˜é‡è¦†ç›–")
    
    # 7. æ£€æŸ¥ç›®å½•ç»“æ„
    required_dirs = ["models", "samples", "logs", "checkpoints"]
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            warnings.append(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {dir_name}")
            recommendations.append(f"ğŸ’¡ å»ºè®®åˆ›å»ºç›®å½•: mkdir {dir_name}")
    
    # 8. è¾“å‡ºæ£€æŸ¥ç»“æœ
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ¯ æ£€æŸ¥ç»“æœæ±‡æ€»")
    logger.info("=" * 50)
    
    if issues_found:
        logger.info("âŒ å‘ç°é—®é¢˜:")
        for issue in issues_found:
            logger.info(f"   {issue}")
    else:
        logger.info("âœ… æœªå‘ç°ä¸¥é‡é…ç½®é—®é¢˜")
    
    if warnings:
        logger.info("\nâš ï¸ è­¦å‘Šäº‹é¡¹:")
        for warning in warnings:
            logger.info(f"   {warning}")
    
    if recommendations:
        logger.info("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for rec in recommendations:
            logger.info(f"   {rec}")
    
    # 9. ç”Ÿæˆé…ç½®æŠ¥å‘Š
    report = {
        "config_check_summary": {
            "issues_count": len(issues_found),
            "warnings_count": len(warnings),
            "recommendations_count": len(recommendations),
            "config_file_exists": os.path.exists(config_file),
            "current_config": {
                "batch_size": batch_size,
                "train_size": train_size,
                "model_save_threshold": model_threshold,
                "mixed_precision": mixed_precision,
                "data_strategy": data_strategy
            }
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    os.makedirs("logs", exist_ok=True)
    with open("logs/config_check_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: logs/config_check_report.json")
    
    return len(issues_found) == 0


def generate_recommended_config():
    """ç”Ÿæˆæ¨èé…ç½®æ–‡ä»¶"""
    logger.info("\nğŸ”§ ç”Ÿæˆæ¨èé…ç½®...")
    
    # æ£€æµ‹æ˜¾å¡ç±»å‹ï¼ˆç®€å•å¯å‘å¼ï¼‰
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
            # æ ¹æ®æ˜¾å¡æ¨èé…ç½®
            if "4060" in gpu_name or "4070" in gpu_name:
                recommended_batch_size = 128
                recommended_workers = 8
            elif "3060" in gpu_name or "1660" in gpu_name:
                recommended_batch_size = 64
                recommended_workers = 6
            elif "4090" in gpu_name or "3090" in gpu_name:
                recommended_batch_size = 256
                recommended_workers = 12
            else:
                recommended_batch_size = 64
                recommended_workers = 4
            
            logger.info(f"ğŸ® æ£€æµ‹åˆ°æ˜¾å¡: {gpu_name} ({gpu_memory:.1f}GB)")
            logger.info(f"ğŸ’¡ æ¨èbatch_size: {recommended_batch_size}")
            
        else:
            logger.info("âš ï¸ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUé»˜è®¤é…ç½®")
            recommended_batch_size = 32
            recommended_workers = 4
    except:
        recommended_batch_size = 64
        recommended_workers = 4
    
    recommended_config = {
        "training": {
            "batch_size": recommended_batch_size,
            "model_save_threshold": 0.95,
            "epoch": 50
        },
        "data": {
            "train_size": 200000,
            "validate_size": 10000,
            "dataloader_workers": recommended_workers,
            "data_strategy": "adaptive"
        },
        "hardware": {
            "mixed_precision": True,
            "compile_model": False,
            "memory_efficient": False
        }
    }
    
    # ä¿å­˜æ¨èé…ç½®
    output_file = "configs/recommended_config.jsonc"
    os.makedirs("configs", exist_ok=True)
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("// è‡ªåŠ¨ç”Ÿæˆçš„æ¨èé…ç½®\n")
        f.write("// åŸºäºæ‚¨çš„ç¡¬ä»¶ç¯å¢ƒä¼˜åŒ–\n")
        json.dump(recommended_config, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ æ¨èé…ç½®å·²ä¿å­˜: {output_file}")
    logger.info("ğŸ’¡ æ‚¨å¯ä»¥å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º train_config.jsonc ä½¿ç”¨")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é…ç½®å†²çªæ£€æŸ¥å·¥å…·")
    parser.add_argument("--generate", action="store_true", help="ç”Ÿæˆæ¨èé…ç½®æ–‡ä»¶")
    parser.add_argument("--fix", action="store_true", help="è‡ªåŠ¨ä¿®å¤å¸¸è§é—®é¢˜")
    
    args = parser.parse_args()
    
    # æ‰§è¡Œé…ç½®æ£€æŸ¥
    is_config_ok = check_config_conflicts()
    
    if args.generate:
        generate_recommended_config()
    
    if args.fix:
        logger.info("\nğŸ”§ è‡ªåŠ¨ä¿®å¤åŠŸèƒ½æš‚æœªå®ç°")
        logger.info("ğŸ’¡ è¯·æ ¹æ®ä¸Šè¿°å»ºè®®æ‰‹åŠ¨è°ƒæ•´é…ç½®")
    
    # è¿”å›çŠ¶æ€ç 
    return 0 if is_config_ok else 1


if __name__ == "__main__":
    exit(main()) 
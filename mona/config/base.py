"""
åˆ†å±‚é…ç½®ç®¡ç†ç³»ç»Ÿ
æ”¯æŒç¯å¢ƒå˜é‡ã€é…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°çš„å¤šå±‚çº§é…ç½®
æ•´åˆç°æœ‰é…ç½®å¹¶æ·»åŠ æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
"""

import os
import json
import re
from typing import Dict, Any, Optional
from pathlib import Path


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ - æ”¯æŒå¤šå±‚çº§é…ç½®åŠ è½½"""
    
    def __init__(self, config_file: Optional[str] = None):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºconfigs/train_config.jsonc
        """
        # æ›´æ–°é»˜è®¤é…ç½®æ–‡ä»¶ä¸ºJSONCæ ¼å¼
        self.config_file = config_file or "configs/train_config.jsonc"
        self._config = self._load_base_config()
        self._apply_env_overrides()
    
    def _remove_json_comments(self, content: str) -> str:
        """ç§»é™¤JSONCæ ¼å¼çš„æ³¨é‡Š"""
        # ç§»é™¤å•è¡Œæ³¨é‡Š // ...
        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
        
        # ç§»é™¤å¤šè¡Œæ³¨é‡Š /* ... */
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        
        # ç§»é™¤æœ«å°¾é€—å·ï¼ˆJSONCå…è®¸ï¼Œä½†æ ‡å‡†JSONä¸å…è®¸ï¼‰
        content = re.sub(r',(\s*[}\]])', r'\1', content)
        
        return content
    
    def _load_json_with_comments(self, file_path: str) -> dict:
        """åŠ è½½æ”¯æŒæ³¨é‡Šçš„JSONæ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤æ³¨é‡Š
        clean_content = self._remove_json_comments(content)
        
        # è§£æJSON
        return json.loads(clean_content)
    
    def _load_base_config(self) -> Dict[str, Any]:
        """åŠ è½½åŸºç¡€é…ç½®ï¼Œæ•´åˆåŸæœ‰é…ç½®"""
        # ğŸ¯ ç®€åŒ–é»˜è®¤é…ç½® - ä»…ä¿ç•™æ ¸å¿ƒå¿…éœ€é¡¹ï¼Œå…¶ä»–é€šè¿‡é…ç½®æ–‡ä»¶è®¾ç½®
        base_config = {
            # æ¨¡å‹å‚æ•° - æ¶æ„ç›¸å…³ï¼Œä¸€èˆ¬ä¸å˜
            "model": {
                "height": 32,                 # å›ºå®šè¾“å…¥é«˜åº¦
                "train_width": 384,           # é»˜è®¤è®­ç»ƒå®½åº¦
                "lexicon_size": None,         # åŠ¨æ€è®¡ç®—
            },
            
            # è®­ç»ƒå‚æ•° - å»ºè®®é€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´
            "training": {
                "batch_size": 64,             # ğŸ”§ ä¿å®ˆé»˜è®¤å€¼ï¼Œé€‚é…å¤§å¤šæ•°æ˜¾å¡
                "epoch": 50,
                "learning_rate": 1.0,         # Adadeltaé»˜è®¤å­¦ä¹ ç‡
                "optimizer": "adadelta",
                "gradient_clip_norm": 1.0,
                "print_per": 100,             # æ—¥å¿—è¾“å‡ºé¢‘ç‡
                "save_per": 600,              # éªŒè¯ä¿å­˜é¢‘ç‡
                "model_save_threshold": 0.95, # ğŸ¯ é»˜è®¤95%å³ä¿å­˜ï¼Œä¾¿äºè°ƒè¯•
                "early_stopping_patience": 10,
                "unfreeze_backbone_epoch": 0,
            },
            
            # æ•°æ®å‚æ•° - å»ºè®®é€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´
            "data": {
                "train_size": 50000,          # ğŸ”§ å‡å°‘é»˜è®¤å€¼ï¼ŒåŠ å¿«è°ƒè¯•
                "validate_size": 5000,
                "dataloader_workers": 4,      # ğŸ”§ ä¿å®ˆé»˜è®¤å€¼
                "pin_memory": True,
                "online_train": True,
                "online_val": True,
                # ğŸš€ è‡ªé€‚åº”æ•°æ®ç­–ç•¥é…ç½®
                "data_strategy": "adaptive",
                "accuracy_threshold": 0.95,
                "difficult_samples_count": 5000,
                "difficult_samples_ratio": 0.3,
            },
            
            # æ•°æ®å¢å¼º - ç®—æ³•ç›¸å…³ï¼Œä¸€èˆ¬ä¸å˜
            "augmentation": {
                "gaussian_blur_prob": 0.5,
                "random_crop_prob": 0.5,
                "gaussian_noise_std": 1/255,
                "rotation_range": 2,
                "brightness_range": 0.1,
                "contrast_range": 0.1,
            },
            
            # ç¡¬ä»¶ä¼˜åŒ– - æ™ºèƒ½é»˜è®¤å€¼
            "hardware": {
                "mixed_precision": True,      # ğŸš€ ç°ä»£æ˜¾å¡é»˜è®¤å¯ç”¨
                "compile_model": False,       # ğŸ”§ ç¨³å®šæ€§ä¼˜å…ˆï¼Œå¯é€‰å¯ç”¨
                "dataloader_pin_memory": True,
                "dataloader_persistent_workers": True,
                "cuda_benchmark": True,       # ğŸ”¥ å›ºå®šå°ºå¯¸ï¼Œå¯ç”¨ä¼˜åŒ–
                "memory_efficient": False,    # ğŸ”§ é»˜è®¤å…³é—­ï¼Œæ˜¾å­˜ä¸è¶³æ—¶å¯ç”¨
            },
            
            # æ¨¡å‹ä¿å­˜å’Œæ£€æŸ¥ç‚¹
            "checkpoint": {
                "save_best_only": False,
                "save_top_k": 3,
                "monitor_metric": "accuracy",
                "checkpoint_dir": "checkpoints",
                "auto_resume": True,
                "save_interval": 600,
            },
            
            # é¢„è®­ç»ƒæ¨¡å‹
            "pretrain": {
                "enabled": False,
                "model_path": "models/genshin_model.pt",
                "freeze_backbone": False,
                "unfreeze_epoch": 0,
            },
            
            # å®éªŒè·Ÿè¸ª
            "experiment": {
                "enabled": False,
                "project_name": "genshin-ocr",
                "experiment_name": None,
                "tags": [],
                "log_model": True,
            },
            
            # è°ƒè¯•å’Œç›‘æ§
            "debug": {
                "profile_training": False,
                "log_memory_usage": True,
                "save_sample_images": True,
                "validate_data_integrity": False,
                "performance_monitoring": True,
            }
        }
        
        # å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
        if os.path.exists(self.config_file):
            try:
                file_config = self._load_json_with_comments(self.config_file)
                base_config = self._deep_merge(base_config, file_config)
                print(f"âœ… é…ç½®æ–‡ä»¶å·²åŠ è½½: {self.config_file}")
                print(f"ğŸ“ é…ç½®è¦†ç›–è¯´æ˜: æ–‡ä»¶é…ç½® > é»˜è®¤é…ç½® > ç¯å¢ƒå˜é‡")
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {self.config_file}, é”™è¯¯: {e}")
                print("ğŸ”„ ä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            print(f"ğŸ“ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            print("ğŸ’¡ å»ºè®®: å¤åˆ¶ configs/train_config.jsonc.example å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹")
        
        return base_config
    
    def _apply_env_overrides(self):
        """åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–"""
        env_mappings = {
            # è®­ç»ƒå‚æ•°
            "BATCH_SIZE": ("training", "batch_size", int),
            "LEARNING_RATE": ("training", "learning_rate", float),
            "EPOCH": ("training", "epoch", int),
            "MODEL_SAVE_THRESHOLD": ("training", "model_save_threshold", float),
            
            # æ•°æ®å‚æ•°
            "TRAIN_SIZE": ("data", "train_size", int),
            "WORKERS": ("data", "dataloader_workers", int),
            
            # ç¡¬ä»¶ä¼˜åŒ– - å…³é”®ç¯å¢ƒå˜é‡
            "MIXED_PRECISION": ("hardware", "mixed_precision", lambda x: x.lower() == 'true'),
            "COMPILE_MODEL": ("hardware", "compile_model", lambda x: x.lower() == 'true'),
            "CUDA_BENCHMARK": ("hardware", "cuda_benchmark", lambda x: x.lower() == 'true'),
            "MEMORY_EFFICIENT": ("hardware", "memory_efficient", lambda x: x.lower() == 'true'),
        }
        
        for env_key, (section, key, converter) in env_mappings.items():
            env_value = os.getenv(env_key)
            if env_value is not None:
                try:
                    self._config[section][key] = converter(env_value)
                    print(f"âœ… ç¯å¢ƒå˜é‡è¦†ç›–: {env_key} = {self._config[section][key]}")
                except (ValueError, KeyError) as e:
                    print(f"âš ï¸ ç¯å¢ƒå˜é‡ {env_key} è§£æå¤±è´¥: {e}")
    
    def _deep_merge(self, base: dict, override: dict) -> dict:
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        result = base.copy()
        for key, value in override.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        return result
    
    def get(self, section: str, key: str = None, default=None):
        """è·å–é…ç½®å€¼"""
        if key is None:
            return self._config.get(section, default)
        return self._config.get(section, {}).get(key, default)
    
    def set(self, section: str, key: str, value: Any):
        """è®¾ç½®é…ç½®å€¼"""
        if section not in self._config:
            self._config[section] = {}
        self._config[section][key] = value
        print(f"âœ… é…ç½®æ›´æ–°: {section}.{key} = {value}")
    
    def save_config(self, path: Optional[str] = None):
        """ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶"""
        save_path = path or self.config_file
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(self._config, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜: {save_path}")
    
    def get_flat_config(self) -> dict:
        """è·å–æ‰å¹³åŒ–é…ç½®ï¼ˆå‘åå…¼å®¹åŸæœ‰config.pyï¼‰"""
        flat_config = {}
        
        # ç›´æ¥æ˜ å°„åŸæœ‰é…ç½®é”®
        flat_config.update({
            # æ¨¡å‹å‚æ•°
            "height": self._config["model"]["height"],
            "train_width": self._config["model"]["train_width"],
            
            # è®­ç»ƒå‚æ•°
            "batch_size": self._config["training"]["batch_size"],
            "epoch": self._config["training"]["epoch"],
            "print_per": self._config["training"]["print_per"],
            "save_per": self._config["training"]["save_per"],
            "model_save_threshold": self._config["training"]["model_save_threshold"],
            "unfreeze_backbone_epoch": self._config["training"]["unfreeze_backbone_epoch"],
            
            # æ•°æ®å‚æ•°
            "train_size": self._config["data"]["train_size"],
            "validate_size": self._config["data"]["validate_size"],
            "dataloader_workers": self._config["data"]["dataloader_workers"],
            "online_train": self._config["data"]["online_train"],
            "online_val": self._config["data"]["online_val"],
            
            # é¢„è®­ç»ƒ
            "pretrain": self._config["pretrain"]["enabled"],
            "pretrain_name": self._config["pretrain"]["model_path"].split('/')[-1],
            
            # æ–°å¢æ€§èƒ½ä¼˜åŒ–å‚æ•°
            "mixed_precision": self._config["hardware"]["mixed_precision"],
            "compile_model": self._config["hardware"]["compile_model"],
            "cuda_benchmark": self._config["hardware"]["cuda_benchmark"],
            "memory_efficient": self._config["hardware"]["memory_efficient"],
        })
        
        return flat_config
    
    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("ğŸš€ åŸç¥OCRè®­ç»ƒé…ç½®æ‘˜è¦")
        print("=" * 50)
        
        # è®­ç»ƒé…ç½®
        training = self._config["training"]
        print(f"ğŸ“Š è®­ç»ƒé…ç½®:")
        print(f"   æ‰¹æ¬¡å¤§å°: {training['batch_size']}")
        print(f"   è®­ç»ƒè½®æ•°: {training['epoch']}")
        print(f"   ä¿å­˜é˜ˆå€¼: {training['model_save_threshold']}")
        
        # ç¡¬ä»¶ä¼˜åŒ–
        hardware = self._config["hardware"]
        print(f"ğŸ”§ ç¡¬ä»¶ä¼˜åŒ–:")
        print(f"   æ··åˆç²¾åº¦: {'âœ…' if hardware['mixed_precision'] else 'âŒ'}")
        print(f"   æ¨¡å‹ç¼–è¯‘: {'âœ…' if hardware['compile_model'] else 'âŒ'}")
        print(f"   CUDAä¼˜åŒ–: {'âœ…' if hardware['cuda_benchmark'] else 'âŒ'}")
        
        # æ•°æ®é…ç½®
        data = self._config["data"]
        print(f"ğŸ“¦ æ•°æ®é…ç½®:")
        print(f"   è®­ç»ƒæ ·æœ¬: {data['train_size']:,}")
        print(f"   éªŒè¯æ ·æœ¬: {data['validate_size']:,}")
        print(f"   å·¥ä½œçº¿ç¨‹: {data['dataloader_workers']}")
        
        print("=" * 50)
    
    @property
    def training(self) -> dict:
        """è®­ç»ƒé…ç½®"""
        return self._config["training"]
    
    @property
    def data(self) -> dict:
        """æ•°æ®é…ç½®"""
        return self._config["data"]
    
    @property
    def model(self) -> dict:
        """æ¨¡å‹é…ç½®"""
        return self._config["model"]
    
    @property
    def hardware(self) -> dict:
        """ç¡¬ä»¶é…ç½®"""
        return self._config["hardware"]


# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
config_manager = ConfigManager()

# å‘åå…¼å®¹çš„é…ç½®å­—å…¸
config = config_manager.get_flat_config()

# æ‰“å°é…ç½®æ‘˜è¦
if __name__ == "__main__":  # åªåœ¨ç›´æ¥è¿è¡Œæ¨¡å—æ—¶æ‰“å°ï¼Œä¸åœ¨å¯¼å…¥æ—¶æ‰“å°
    config_manager.print_config_summary() 